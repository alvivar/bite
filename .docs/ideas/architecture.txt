
    v5
        Based on the prototype github.com/alvivar/sock everything changed from
        *v3* to MIO + Multi-thread.


    v4 (bananas and incomplete)
        Data <- immutable, never changing, authoritative, no need for a lock data

        Database thread  // this is still a limitation (less so)
            OwnCopyOfData <- it is what is says
            On changeset -> apply it on the local copy and swap the copy with Data atomically (maybe atomic pointer here?)

        Handler threads
            1. Receive an instruction (blocking)
            2. Send a message to the database thread
            3. If the message is a write
                4. Compose a changeset and send it to the database thread
                5. Reply with ACK
            4. Else if the message is a read
                6. Read and reply

        Main thread
            1. Listen to connections
            2. Spawn handler threads for each connection (for now, no need to keep track of the handle) (no mutex needed for the socket)


    v3
        Storage thread  // this is just to write the file
            On Write Message => write to file

        Database thread  // this is still a limitation
            OnMsg -> do stuff and reply the sender

        Handler threads
            1. Receive an instruction (blocking)
            2. Send a message to the database thread
            3. If the message has a response
                4. Wait for a message from the database thread (HOW? we could send our communication channel with the message) (blocking)
                5. Send the result (blocking)
            6. Else send an acknowledgement response (blocking)

        Main thread
            1. Listen to connections
            2. Spawn handler threads for each connection (for now, no need to keep track of the handle) (no mutex needed for the socket)


    v3 (simplest)
        Data (this is not a thread)

        Write to disk thred
            1. On message -> Write Data to disk

        Handler threads
            1. Receive an instruction (blocking)
            2. Execute the instruction (synchronously accessed data using an RwLock) <- this is also a source of inefficiency
            3. Send a message to the Write-to-disk-thread
            4. Send the result (blocking)

        Main thread
            1. Listen to connections
            2. Spawn handler threads for each connection (for now, no need to keep track of the handle) (no mutex needed for the socket)


    v2
        Clients listener thread
            On Client
                Send socket to the next Worker

        Worker
            Thread
                Listen to Messages Non blocking
                    On New client
                        Add client to the client queue

                Loop over the socket queue Non blocking
                    Read line socket message
                    Parse socket into Process
                    Send Process and socket to Main thread

        Main thread
            [A] Listening Worker messages (blocking) // has to wait for B and C (bad)
                On Process (Some message)
                    BTreeMap update
                    [C] BTreeMap file save
                    [B] Write the result in the Worker client socket


    v1
        A Hack.

        Code Review:

            Current: Listening on the same thread as you're processing things
            Better: Listen on one thread, handle connections on another

            Current one:
            1. [a] Lock the stream
            2. [a] Read a message
            3. Launch a thread that will process the message (expensive because launching a new thread is expensive)
            4. [a] Lock the stream within this thread
            5. [a] Send the reply within this thread

            Problems:
            1. Lots of lockign between [a]
            2. Launching a thread is expensive, we're doing it for every message

            Better one:
            1. Thread pool for however many CPU cores you have to handle the messages
            2. An non-blocking message queue to feed messages to the thread pool
            3. A blocking message queue to feed results from the thread pool to main thread
            4. Only your main thread handles any I/O (I/O is slow)

            Benefits:
            1. The thread pool ..
            2. One thread handles IO and n threads handle messages as fast as your CPU can do on each core (no locking, ever)


            #[derive(Debug)]
            enum Command {
                Get(String),
                Set(String, String),
            }

            #[derive(Debug)]
            enum Message {
                Resp(String),
            }

            struct Worker {
                join_handle: thread::JoinHandle<()>,
                cmd_sndr: mpsc::Sender<Command>,
            }

            impl Worker {
                pub fn new(msg_sndr: mpsc::Sender<Message>) -> Self {
                    let (cmd_sndr, cmd_recv) = mpsc::channel::<Command>();
                    let join_handle = thread::spawn(move || Self::worker(cmd_recv, msg_sndr));
                    Self {
                        join_handle,
                        cmd_sndr,
                    }
                }

                pub fn command(&self, cmd: Command) {
                    self.cmd_sndr.send(cmd).unwrap()
                }

                fn worker(cmd_recv: mpsc::Receiver<Command>, msg_sndr: mpsc::Sender<Message>) {
                    loop {
                        let cmd = cmd_recv.recv().unwrap();
                        println!("{:?}", &cmd);
                        match cmd {
                            Command::Get(key) => {
                                msg_sndr.send(Message::Resp("GET".to_owned())).unwrap();
                            }
                            Command::Set(key, val) => {
                                msg_sndr.send(Message::Resp("SET".to_owned())).unwrap();
                            }
                        }
                    }
                }
            }
